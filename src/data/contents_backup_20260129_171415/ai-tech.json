{
  "01_object-detection/yolo-intro": {
    "id": "01_object-detection/yolo-intro",
    "title": "YOLO ì‹¤ì „ ì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ - Java + Python + AI í†µí•©",
    "category": "ai-tech",
    "subCategory": "01_object-detection",
    "language": "Python",
    "description": "YOLO AI ì„œë²„ë¥¼ Spring Bootì™€ ì—°ë™í•˜ëŠ” MSA ì•„í‚¤í…ì²˜ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤. ì™œ Javaì™€ Pythonì„ í•¨ê»˜ ì“°ëŠ”ì§€, ì‹¤ì œ í”„ë¡œë•ì…˜ ì½”ë“œ ë¦¬ë·°, Docker ë°°í¬, ê·¸ë¦¬ê³  Spring Boot ì—°ë™ê¹Œì§€ Big Pictureë¥¼ ê·¸ë¦½ë‹ˆë‹¤.",
    "isPlaceholder": false,
    "sections": [
      {
        "type": "concept",
        "title": "ğŸ¯ Big Picture: ì™œ Javaì™€ Pythonì„ í•¨ê»˜ ì“°ëŠ”ê°€?",
        "content": "**í˜¸í…” ë¹„ìœ ë¡œ ì´í•´í•˜ëŠ” MSA ì•„í‚¤í…ì²˜**\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                      ğŸ¨ AI ì„œë¹„ìŠ¤ í˜¸í…”                        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                             â”‚\nâ”‚   ğŸ‘” Java (Spring Boot) = í˜¸í…” ë§¤ë‹ˆì €                        â”‚\nâ”‚   â”œâ”€â”€ ê³ ê° ì‘ëŒ€ (API Gateway)                               â”‚\nâ”‚   â”œâ”€â”€ ì˜ˆì•½ ê´€ë¦¬ (íŠ¸ëœì­ì…˜, DB)                               â”‚\nâ”‚   â”œâ”€â”€ íšŒê³„ ì²˜ë¦¬ (ê²°ì œ, ì •ì‚°)                                 â”‚\nâ”‚   â””â”€â”€ ì§ì› ê´€ë¦¬ (ì¸ì¦, ê¶Œí•œ)                                 â”‚\nâ”‚                                                             â”‚\nâ”‚   ğŸ‘¨â€ğŸ³ Python (FastAPI) = ì „ë¬¸ ì…°í”„                           â”‚\nâ”‚   â”œâ”€â”€ AI ìš”ë¦¬ ì „ë¬¸ (YOLO, Whisper, OCR)                     â”‚\nâ”‚   â”œâ”€â”€ íŠ¹ìˆ˜ ì¬ë£Œ ë‹¤ë£¨ê¸° (PyTorch, TensorFlow)                â”‚\nâ”‚   â””â”€â”€ ë ˆì‹œí”¼ ì‹¤í—˜ (Jupyter, ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘)               â”‚\nâ”‚                                                             â”‚\nâ”‚   ğŸ“ REST API = ì£¼ë¬¸ì„œ                                      â”‚\nâ”‚   â””â”€â”€ ë§¤ë‹ˆì €ê°€ ì…°í”„ì—ê²Œ ìš”ë¦¬ ì£¼ë¬¸í•˜ëŠ” í‘œì¤€ ì–‘ì‹              â”‚\nâ”‚                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**ì™œ ì´ë ‡ê²Œ ë‚˜ëˆ„ëŠ”ê°€?**\n\n| ì—­í•  | Java (Spring Boot) | Python (FastAPI) |\n|------|-------------------|------------------|\n| **ê°•ì ** | ì—”í„°í”„ë¼ì´ì¦ˆ, íŠ¸ëœì­ì…˜, ë³´ì•ˆ | AI/ML, ë°ì´í„° ì²˜ë¦¬ |\n| **ìƒíƒœê³„** | JPA, Security, Cloud | PyTorch, Ultralytics, HuggingFace |\n| **ì„±ëŠ¥** | ì•ˆì •ì ì¸ ë™ì‹œì„± ì²˜ë¦¬ | GPU ì—°ì‚° ìµœì í™” |\n| **ìœ ì§€ë³´ìˆ˜** | ì •ì  íƒ€ì…, ì»´íŒŒì¼ ê²€ì¦ | ë¹ ë¥¸ ì‹¤í—˜/ë°°í¬ |\n\n**í•µì‹¬ í¬ì¸íŠ¸:**\n- \"ëª¨ë“  ê±¸ í•˜ë‚˜ì˜ ì–¸ì–´ë¡œ\" í•˜ë©´ **ë¹„íš¨ìœ¨ì **\n- ê° ì–¸ì–´ê°€ **ê°€ì¥ ì˜í•˜ëŠ” ì¼**ì— ì§‘ì¤‘\n- REST APIë¡œ **ëŠìŠ¨í•œ ê²°í•©** â†’ ë…ë¦½ ë°°í¬/í™•ì¥ ê°€ëŠ¥"
      },
      {
        "type": "concept",
        "title": "ğŸ”„ ì „ì²´ ì„œë¹„ìŠ¤ íë¦„ (Spring Boot â†” FastAPI)",
        "content": "**K-MaaS ë²ˆí˜¸íŒ ì¸ì‹ ì„œë¹„ìŠ¤ íë¦„**\n\n```\n[ì‚¬ìš©ì ì•±]     [Spring Boot]        [Python AI Server]      [ì‘ë‹µ]\n    â”‚               â”‚                      â”‚                   â”‚\n    â”‚  â‘  ì´ë¯¸ì§€    â”‚                      â”‚                   â”‚\n    â”‚  ì—…ë¡œë“œ      â”‚                      â”‚                   â”‚\n    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                      â”‚                   â”‚\n    â”‚               â”‚  â‘¡ HTTP POST        â”‚                   â”‚\n    â”‚               â”‚  /api/v1/license-   â”‚                   â”‚\n    â”‚               â”‚  plate/detect       â”‚                   â”‚\n    â”‚               â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                   â”‚\n    â”‚               â”‚                      â”‚                   â”‚\n    â”‚               â”‚                      â”‚ â‘¢ YOLO íƒì§€       â”‚\n    â”‚               â”‚                      â”‚    + OCR ì¸ì‹     â”‚\n    â”‚               â”‚                      â”‚                   â”‚\n    â”‚               â”‚  â‘£ JSON ì‘ë‹µ        â”‚                   â”‚\n    â”‚               â”‚  {plate_number,      â”‚                   â”‚\n    â”‚               â”‚   confidence, bbox}  â”‚                   â”‚\n    â”‚               â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                   â”‚\n    â”‚               â”‚                      â”‚                   â”‚\n    â”‚               â”‚ â‘¤ DB ì €ì¥           â”‚                   â”‚\n    â”‚               â”‚    + ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§   â”‚                   â”‚\n    â”‚               â”‚                      â”‚                   â”‚\n    â”‚  â‘¥ ìµœì¢… ì‘ë‹µ â”‚                      â”‚                   â”‚\n    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚                   â”‚\n```\n\n**ì™œ Spring Bootê°€ ì§ì ‘ YOLOë¥¼ ì•ˆ ëŒë¦¬ë‚˜?**\n1. **ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ì„±**: PyTorch, UltralyticsëŠ” Python ì „ìš©\n2. **GPU ê´€ë¦¬**: Pythonì´ CUDA ì—°ë™ì— ìµœì í™”\n3. **ëª¨ë¸ ì—…ë°ì´íŠ¸**: AI ëª¨ë¸ë§Œ ë…ë¦½ì ìœ¼ë¡œ ë°°í¬ ê°€ëŠ¥\n4. **ì¥ì•  ê²©ë¦¬**: AI ì„œë²„ ì¥ì• ê°€ ì „ì²´ ì„œë¹„ìŠ¤ì— ì˜í–¥ ì•ˆ ì¤Œ"
      },
      {
        "type": "code",
        "language": "python",
        "title": "ğŸ“ FastAPI YOLO ì„œë²„ ì½”ë“œ ë¦¬ë·° (main.py)",
        "code": "\"\"\"\nK-MaaS FastAPI AI Server - í•µì‹¬ ì½”ë“œ ë¶„ì„\n\nì´ ì„œë²„ê°€ í•˜ëŠ” ì¼:\n1. ë²ˆí˜¸íŒ ì¸ì‹ (YOLO + OCR)\n2. ê°ì²´ íƒì§€ (YOLO)\n3. ìŒì„± ì¸ì‹ (Whisper)\n4. ê°ì„± ë¶„ì„, í‚¤ì›Œë“œ ì¶”ì¶œ\n\nSpring Bootì™€ ì—°ë™ë˜ëŠ” AI ì²˜ë¦¬ ì „ë‹´ ì„œë²„\n\"\"\"\nfrom fastapi import FastAPI, UploadFile, File, HTTPException, Header\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\nimport io\nimport time\nimport logging\nimport uuid\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 1. FastAPI ì•± ìƒì„± - ì™œ Flaskê°€ ì•„ë‹ˆë¼ FastAPI?\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# - async/await ë„¤ì´í‹°ë¸Œ ì§€ì› â†’ ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ì— ìœ ë¦¬\n# - Pydantic ìë™ ê²€ì¦ â†’ DTO íƒ€ì… ì•ˆì „ì„±\n# - ìë™ Swagger ë¬¸ì„œ â†’ Spring Boot ê°œë°œìì™€ í˜‘ì—… í¸ë¦¬\n# - ì„±ëŠ¥: Flask ëŒ€ë¹„ 2~3ë°° ë¹ ë¦„\n\napp = FastAPI(\n    title=\"K-MaaS AI Server\",\n    description=\"ë²ˆí˜¸íŒ ì¸ì‹, ê°ì²´ íƒì§€, ìŒì„± ì¸ì‹ API\",\n    version=\"2.0.0\"\n)\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 2. CORS ì„¤ì • - Spring Bootì—ì„œ í˜¸ì¶œí•  ìˆ˜ ìˆê²Œ\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# ë‹¤ë¥¸ ë„ë©”ì¸(Spring Boot: 8080)ì—ì„œ ì´ ì„œë²„(8000)ë¥¼ \n# í˜¸ì¶œí•˜ë ¤ë©´ CORS í—ˆìš© í•„ìˆ˜\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],        # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ë§Œ!\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 3. ëª¨ë¸ ì‹±ê¸€í†¤ íŒ¨í„´ - ì™œ ì´ë ‡ê²Œ í•˜ëŠ”ê°€?\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# YOLO ëª¨ë¸ ë¡œë”© = ìˆ˜ ì´ˆ ì†Œìš” + ìˆ˜ë°± MB ë©”ëª¨ë¦¬\n# ë§¤ ìš”ì²­ë§ˆë‹¤ ë¡œë“œí•˜ë©´ â†’ ëŠë¦¬ê³  ë©”ëª¨ë¦¬ í„°ì§\n# ì‹±ê¸€í†¤: ìµœì´ˆ 1ë²ˆë§Œ ë¡œë“œ, ì´í›„ ì¬ì‚¬ìš©\n\nyolo_model = None\n\ndef get_yolo_model():\n    \"\"\"YOLO ëª¨ë¸ ì§€ì—° ë¡œë”© (Lazy Loading) + ì‹±ê¸€í†¤\"\"\"\n    global yolo_model\n    if yolo_model is None:  # ì•„ì§ ì•ˆ ë§Œë“¤ì—ˆìœ¼ë©´\n        from ultralytics import YOLO\n        yolo_model = YOLO(\"yolov8n.pt\")  # ì—¬ê¸°ì„œ ë‹¤ìš´ë¡œë“œ + ë¡œë“œ\n    return yolo_model\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 4. Pydantic ëª¨ë¸ - Spring Boot DTOì™€ 1:1 ë§¤í•‘\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# Pythonì˜ ì‘ë‹µ êµ¬ì¡° = Javaì˜ Response DTOì™€ ë™ì¼í•´ì•¼\n# JSON ì§ë ¬í™”/ì—­ì§ë ¬í™”ê°€ ë§¤ë„ëŸ½ê²Œ ë™ì‘\n\nclass BoundingBox(BaseModel):\n    \"\"\"ë²ˆí˜¸íŒ ì˜ì—­ ì¢Œí‘œ - Springì˜ BoundingBox.javaì™€ ë™ì¼\"\"\"\n    x: int\n    y: int\n    width: int\n    height: int\n\nclass LicensePlateResponse(BaseModel):\n    \"\"\"\n    ë²ˆí˜¸íŒ ì¸ì‹ ì‘ë‹µ ëª¨ë¸\n    â†’ Spring Bootì˜ LicensePlateResponse.javaì™€ 1:1 ë§¤í•‘\n    \"\"\"\n    success: bool\n    request_id: Optional[str] = None\n    plate_number: Optional[str] = Field(None, description=\"ì¸ì‹ëœ ë²ˆí˜¸íŒ\")\n    confidence: Optional[float] = Field(None, ge=0, le=1)\n    bounding_box: Optional[BoundingBox] = None\n    processing_time_ms: Optional[int] = None\n    error_message: Optional[str] = None"
      },
      {
        "type": "code",
        "language": "python",
        "title": "ğŸš— ë²ˆí˜¸íŒ ì¸ì‹ API í•µì‹¬ ë¡œì§",
        "code": "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# ë²ˆí˜¸íŒ ì¸ì‹ API - YOLO + OCR íŒŒì´í”„ë¼ì¸\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n@app.post(\"/api/v1/license-plate/detect\", response_model=LicensePlateResponse)\nasync def detect_license_plate(\n    file: UploadFile = File(..., description=\"ì°¨ëŸ‰ ì´ë¯¸ì§€\"),\n    x_request_id: Optional[str] = Header(None, alias=\"X-Request-ID\")\n):\n    \"\"\"\n    ğŸš— K-MaaS ë²ˆí˜¸íŒ ì¸ì‹ API\n    \n    ì²˜ë¦¬ íë¦„:\n    1. ì´ë¯¸ì§€ ìˆ˜ì‹  (multipart/form-data)\n    2. YOLOë¡œ ì°¨ëŸ‰/ë²ˆí˜¸íŒ ì˜ì—­ íƒì§€\n    3. OCRë¡œ ë²ˆí˜¸íŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n    4. JSON ì‘ë‹µ ë°˜í™˜\n    \n    Spring Bootì˜ AiService.detectLicensePlate()ì—ì„œ í˜¸ì¶œ\n    \"\"\"\n    start_time = time.time()\n    request_id = x_request_id or str(uuid.uuid4())\n    \n    try:\n        from PIL import Image\n        import numpy as np\n        import easyocr\n        \n        # 1ë‹¨ê³„: ì´ë¯¸ì§€ ë¡œë“œ (Springì—ì„œ ë°›ì€ MultipartFile)\n        contents = await file.read()  # asyncë¡œ ë¹„ë™ê¸° ì½ê¸°\n        image = Image.open(io.BytesIO(contents))\n        image_np = np.array(image)\n        \n        # 2ë‹¨ê³„: YOLOë¡œ ê°ì²´ íƒì§€ (ì°¨ëŸ‰ ì°¾ê¸°)\n        model = get_yolo_model()  # ì‹±ê¸€í†¤ì—ì„œ ê°€ì ¸ì˜´\n        results = model(image)\n        \n        main_plate = None\n        main_confidence = 0\n        \n        # 3ë‹¨ê³„: íƒì§€ëœ ì°¨ëŸ‰ì—ì„œ ë²ˆí˜¸íŒ ì˜ì—­ ì¶”ì¶œ\n        for r in results:\n            for box in r.boxes:\n                class_name = r.names[int(box.cls)]\n                confidence = float(box.conf)\n                \n                # ì°¨ëŸ‰ í´ë˜ìŠ¤ì¸ ê²½ìš° (car, truck, bus...)\n                if class_name in ['car', 'truck', 'bus', 'motorcycle']:\n                    x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n                    \n                    # ì°¨ëŸ‰ í•˜ë‹¨ 30%ë¥¼ ë²ˆí˜¸íŒ ì˜ì—­ìœ¼ë¡œ ê°€ì •\n                    # (ì‹¤ì œë¡œëŠ” ë²ˆí˜¸íŒ ì „ìš© YOLO ëª¨ë¸ ì‚¬ìš© ê¶Œì¥)\n                    plate_y1 = y1 + int((y2 - y1) * 0.7)\n                    plate_region = image_np[plate_y1:y2, x1:x2]\n                    \n                    # 4ë‹¨ê³„: OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n                    if plate_region.size > 0:\n                        reader = easyocr.Reader(['ko', 'en'])\n                        ocr_results = reader.readtext(plate_region)\n                        \n                        if ocr_results:\n                            plate_text = ''.join([t[1] for t in ocr_results])\n                            plate_text = plate_text.replace(' ', '').upper()\n                            \n                            if confidence > main_confidence:\n                                main_confidence = confidence\n                                main_plate = {\n                                    \"number\": plate_text,\n                                    \"confidence\": confidence,\n                                    \"bbox\": BoundingBox(x=x1, y=y1, width=x2-x1, height=y2-y1)\n                                }\n        \n        processing_time = int((time.time() - start_time) * 1000)\n        \n        # 5ë‹¨ê³„: ê²°ê³¼ ë°˜í™˜ (Spring Bootê°€ ë°›ì„ JSON)\n        if main_plate:\n            return LicensePlateResponse(\n                success=True,\n                request_id=request_id,\n                plate_number=main_plate[\"number\"],\n                confidence=main_plate[\"confidence\"],\n                bounding_box=main_plate[\"bbox\"],\n                processing_time_ms=processing_time\n            )\n        else:\n            return LicensePlateResponse(\n                success=False,\n                request_id=request_id,\n                processing_time_ms=processing_time,\n                error_message=\"ë²ˆí˜¸íŒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"\n            )\n            \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))"
      },
      {
        "type": "code",
        "language": "dockerfile",
        "title": "ğŸ³ Docker ë°°í¬ ì„¤ì • (Dockerfile ë¶„ì„)",
        "code": "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# Python AI ì„œë²„ Dockerfile - ë¼ì¸ë³„ ìƒì„¸ ì„¤ëª…\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# 1. ë² ì´ìŠ¤ ì´ë¯¸ì§€ ì„ íƒ\n# python:3.11-slim = ë°ë¹„ì•ˆ ê¸°ë°˜ ê²½ëŸ‰ ì´ë¯¸ì§€ (ì•½ 150MB)\n# ì™œ slim? â†’ ì „ì²´ ì´ë¯¸ì§€ëŠ” 1GB+, slimì€ í•„ìˆ˜ë§Œ í¬í•¨\nFROM python:3.11-slim\n\n# 2. ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •\n# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ /app í´ë”ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‘ì—…\nWORKDIR /app\n\n# 3. ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜ â­ ì¤‘ìš”!\n# OpenCV, ì´ë¯¸ì§€ ì²˜ë¦¬ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤\nRUN apt-get update && apt-get install -y \\\n    ffmpeg \\          # ë¹„ë””ì˜¤/ì˜¤ë””ì˜¤ ì²˜ë¦¬ (Whisperìš©)\n    libsm6 \\          # X11 ì„¸ì…˜ ê´€ë¦¬ (OpenCV í•„ìˆ˜)\n    libxext6 \\        # X11 í™•ì¥ (OpenCV í•„ìˆ˜)\n    libgl1-mesa-glx \\ # OpenGL (ì´ë¯¸ì§€ ë Œë”ë§)\n    && rm -rf /var/lib/apt/lists/*  # ìºì‹œ ì‚­ì œë¡œ ì´ë¯¸ì§€ ê²½ëŸ‰í™”\n\n# 4. Python íŒ¨í‚¤ì§€ ì„¤ì¹˜\n# requirements.txtë¥¼ ë¨¼ì € ë³µì‚¬ â†’ Docker ìºì‹œ í™œìš©\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n# --no-cache-dir: pip ìºì‹œ ì•ˆ ë‚¨ê¹€ â†’ ì´ë¯¸ì§€ í¬ê¸° ê°ì†Œ\n\n# 5. (ì„ íƒ) ë¹Œë“œ ì‹œ ëª¨ë¸ ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œ\n# ì£¼ì„ í•´ì œí•˜ë©´ ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹œ ë‹¤ìš´ë¡œë“œ ì•ˆ í•´ë„ ë¨\n# ë‹¨ì : ì´ë¯¸ì§€ í¬ê¸° ì¦ê°€ (yolov8n.pt = ì•½ 6MB)\n# RUN python -c \"from ultralytics import YOLO; YOLO('yolov8n.pt')\"\n\n# 6. ì†ŒìŠ¤ ì½”ë“œ ë³µì‚¬\n# ì˜ì¡´ì„± ì„¤ì¹˜ í›„ ë³µì‚¬ â†’ ì½”ë“œ ë³€ê²½ ì‹œ ì˜ì¡´ì„± ì¬ì„¤ì¹˜ ì•ˆ í•¨\nCOPY . .\n\n# 7. í¬íŠ¸ ë…¸ì¶œ\n# FastAPI ì„œë²„ê°€ ì‚¬ìš©í•  í¬íŠ¸\nEXPOSE 8000\n\n# 8. ì„œë²„ ì‹¤í–‰ ëª…ë ¹\n# uvicorn: ASGI ì„œë²„ (ë¹„ë™ê¸° ì²˜ë¦¬ì— ìµœì í™”)\n# --host 0.0.0.0: ì™¸ë¶€ ì ‘ê·¼ í—ˆìš© (Docker ë„¤íŠ¸ì›Œí¬ìš©)\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]"
      },
      {
        "type": "code",
        "language": "yaml",
        "title": "ğŸ³ Docker Compose - ì „ì²´ ì„œë¹„ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜",
        "code": "# docker-compose.yml\n# Spring Boot + FastAPI + DB + Redis í†µí•© ì‹¤í–‰\n\nversion: '3.8'\n\nservices:\n  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  # 1. Python AI ì„œë²„ (YOLO, Whisper, OCR)\n  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  ai-server:\n    build: ./backend/python-ai-server\n    ports:\n      - \"8000:8000\"\n    environment:\n      - OPENAI_API_KEY=${OPENAI_API_KEY}  # ChatGPT APIìš©\n    volumes:\n      - ./models:/app/models  # ëª¨ë¸ íŒŒì¼ ì˜ì†í™”\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia       # GPU ì‚¬ìš© ì‹œ\n              count: 1\n              capabilities: [gpu]\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  # 2. Spring Boot ë°±ì—”ë“œ (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§, API Gateway)\n  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  spring-backend:\n    build: ./backend/spring-boot\n    ports:\n      - \"8080:8080\"\n    environment:\n      - SPRING_PROFILES_ACTIVE=docker\n      - AI_SERVER_URL=http://ai-server:8000  # Docker ë„¤íŠ¸ì›Œí¬ ë‚´ë¶€ í†µì‹ \n      - DATABASE_URL=jdbc:postgresql://db:5432/kmaas\n    depends_on:\n      - ai-server\n      - db\n      - redis\n\n  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  # 3. PostgreSQL ë°ì´í„°ë² ì´ìŠ¤\n  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  db:\n    image: postgres:15\n    environment:\n      POSTGRES_DB: kmaas\n      POSTGRES_USER: admin\n      POSTGRES_PASSWORD: ${DB_PASSWORD}\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n\n  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  # 4. Redis ìºì‹œ (AI ê²°ê³¼ ìºì‹±, ì„¸ì…˜ ê´€ë¦¬)\n  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  redis:\n    image: redis:7-alpine\n    ports:\n      - \"6379:6379\"\n\nvolumes:\n  postgres_data:"
      },
      {
        "type": "code",
        "language": "java",
        "title": "â˜• Spring Bootì—ì„œ AI ì„œë²„ í˜¸ì¶œí•˜ê¸°",
        "code": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// Spring Boot AiService - FastAPI ì„œë²„ ì—°ë™\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n@Service\n@Slf4j\npublic class AiService {\n\n    private final WebClient webClient;  // ë¹„ë™ê¸° HTTP í´ë¼ì´ì–¸íŠ¸\n    \n    @Value(\"${ai.server.url}\")\n    private String aiServerUrl;  // http://ai-server:8000 (Docker)\n    \n    public AiService(WebClient.Builder webClientBuilder) {\n        this.webClient = webClientBuilder\n            .baseUrl(aiServerUrl)\n            .defaultHeader(HttpHeaders.CONTENT_TYPE, MediaType.MULTIPART_FORM_DATA_VALUE)\n            .build();\n    }\n    \n    /**\n     * ë²ˆí˜¸íŒ ì¸ì‹ API í˜¸ì¶œ\n     * Python AI ì„œë²„ì˜ /api/v1/license-plate/detect ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ\n     */\n    public Mono<LicensePlateResponse> detectLicensePlate(MultipartFile image) {\n        String requestId = UUID.randomUUID().toString();\n        log.info(\"[{}] ë²ˆí˜¸íŒ ì¸ì‹ ìš”ì²­ ì‹œì‘\", requestId);\n        \n        return webClient.post()\n            .uri(\"/api/v1/license-plate/detect\")\n            .header(\"X-Request-ID\", requestId)\n            .body(BodyInserters.fromMultipartData(\n                \"file\", new MultipartInputStreamFileResource(image)\n            ))\n            .retrieve()\n            .onStatus(HttpStatusCode::isError, response -> {\n                log.error(\"[{}] AI ì„œë²„ ì—ëŸ¬: {}\", requestId, response.statusCode());\n                return Mono.error(new AiServiceException(\"AI ì²˜ë¦¬ ì‹¤íŒ¨\"));\n            })\n            .bodyToMono(LicensePlateResponse.class)\n            .doOnSuccess(response -> {\n                if (response.isSuccess()) {\n                    log.info(\"[{}] ë²ˆí˜¸íŒ ì¸ì‹ ì„±ê³µ: {} ({}ms)\", \n                        requestId, response.getPlateNumber(), response.getProcessingTimeMs());\n                }\n            })\n            .timeout(Duration.ofSeconds(30))  // íƒ€ì„ì•„ì›ƒ ì„¤ì •\n            .retryWhen(Retry.backoff(3, Duration.ofSeconds(1)))  // ì¬ì‹œë„\n            .onErrorResume(e -> {\n                log.error(\"[{}] ë²ˆí˜¸íŒ ì¸ì‹ ì‹¤íŒ¨\", requestId, e);\n                return Mono.just(LicensePlateResponse.failure(e.getMessage()));\n            });\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// ì‘ë‹µ DTO - Pythonì˜ LicensePlateResponseì™€ ë™ì¼ êµ¬ì¡°\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n@Data\npublic class LicensePlateResponse {\n    private boolean success;\n    private String requestId;\n    private String plateNumber;      // Python: plate_number (ìë™ ë§¤í•‘)\n    private Double confidence;\n    private BoundingBox boundingBox; // Python: bounding_box\n    private Integer processingTimeMs;\n    private String errorMessage;\n    \n    @Data\n    public static class BoundingBox {\n        private int x, y, width, height;\n    }\n}"
      },
      {
        "type": "tip",
        "title": "ğŸš€ í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸",
        "content": "**1. ë³´ì•ˆ**\n```yaml\n# CORS í”„ë¡œë•ì…˜ ì„¤ì •\nallow_origins: [\"https://yourdomain.com\"]  # * ê¸ˆì§€!\n\n# API ì¸ì¦\nX-API-Key í—¤ë” ê²€ì¦ ì¶”ê°€\n```\n\n**2. ì„±ëŠ¥ ìµœì í™”**\n```python\n# ëª¨ë¸ ì›Œë°ì—… (ì„œë²„ ì‹œì‘ ì‹œ)\n@app.on_event(\"startup\")\nasync def startup():\n    get_yolo_model()  # ë¯¸ë¦¬ ë¡œë“œ\n    \n# GPU ì‚¬ìš© í™•ì¸\nimport torch\nprint(f\"CUDA ì‚¬ìš©: {torch.cuda.is_available()}\")\n```\n\n**3. ëª¨ë‹ˆí„°ë§**\n```yaml\n# Prometheus ë©”íŠ¸ë¦­ ì¶”ê°€\npip install prometheus-fastapi-instrumentator\n\n# ë¡œê·¸ êµ¬ì¡°í™”\nlogger.info(\"ìš”ì²­\", extra={\"request_id\": id, \"latency_ms\": time})\n```\n\n**4. í™•ì¥ì„±**\n```yaml\n# Docker Swarm / K8së¡œ AI ì„œë²„ ìŠ¤ì¼€ì¼ ì•„ì›ƒ\ndeploy:\n  replicas: 3\n  resources:\n    reservations:\n      devices:\n        - driver: nvidia\n          count: 1\n```"
      },
      {
        "type": "tip",
        "title": "ğŸ’¡ í•µì‹¬ ì •ë¦¬: ì–¸ì œ ì´ ì•„í‚¤í…ì²˜ë¥¼ ì“°ëŠ”ê°€?",
        "content": "**ì´ íŒ¨í„´ì´ ì í•©í•œ ê²½ìš°:**\n\nâœ… AI ëª¨ë¸ì´ Python ì „ìš© (PyTorch, TensorFlow)\nâœ… GPU ì—°ì‚°ì´ í•„ìš”í•œ ë¬´ê±°ìš´ ì¶”ë¡ \nâœ… AI íŒ€ê³¼ ë°±ì—”ë“œ íŒ€ì´ ë¶„ë¦¬ëœ ì¡°ì§\nâœ… AI ëª¨ë¸ì„ ìì£¼ ì—…ë°ì´íŠ¸í•´ì•¼ í•  ë•Œ\nâœ… íŠ¸ë˜í”½ì— ë”°ë¼ AI ì„œë²„ë§Œ ìŠ¤ì¼€ì¼ ì•„ì›ƒ í•„ìš”\n\n**ì´ íŒ¨í„´ì´ ê³¼í•œ ê²½ìš°:**\n\nâŒ ê°„ë‹¨í•œ ML (scikit-learn ìˆ˜ì¤€) â†’ Javaì—ì„œ ì§ì ‘ í˜¸ì¶œ ê°€ëŠ¥\nâŒ íŠ¸ë˜í”½ì´ ì ì€ í”„ë¡œí† íƒ€ì… â†’ ë‹¨ì¼ ì„œë²„ë¡œ ì¶©ë¶„\nâŒ íŒ€ì´ ì‘ê³  Pythonë§Œ ì‚¬ìš© â†’ Django/FastAPI ë‹¨ì¼ ìŠ¤íƒ\n\n**ê¸°ì–µí•  í•µì‹¬:**\n```\nSpring Boot = ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ + íŠ¸ëœì­ì…˜ + ì¸ì¦\nFastAPI     = AI ì¶”ë¡  + GPU ì—°ì‚° + ëª¨ë¸ ê´€ë¦¬\nREST API    = ë‘˜ì„ ì—°ê²°í•˜ëŠ” ê³„ì•½ì„œ\n```"
      }
    ]
  },
  "02_image-generation/stable-diffusion": {
    "id": "02_image-generation/stable-diffusion",
    "title": "Stable Diffusion ì´ë¯¸ì§€ ìƒì„±",
    "category": "ai-tech",
    "subCategory": "02_image-generation",
    "language": "Python",
    "description": "í…ìŠ¤íŠ¸ë¡œë¶€í„° ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” Stable Diffusionì˜ ì›ë¦¬ì™€ ì‚¬ìš©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.",
    "isPlaceholder": false,
    "sections": [
      {
        "type": "concept",
        "title": "Stable Diffusionì´ë€?",
        "content": "**Text-to-Image ìƒì„± ëª¨ë¸**\n\ní…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ í•´ë‹¹ ì„¤ëª…ì— ë§ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n\n**í•µì‹¬ êµ¬ì„± ìš”ì†Œ:**\n- **VAE (Variational Autoencoder)**: ì´ë¯¸ì§€ â†” ì ì¬ ê³µê°„ ë³€í™˜\n- **U-Net**: ë…¸ì´ì¦ˆ ì œê±° (Denoising)\n- **Text Encoder (CLIP)**: í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\n\n**ë™ì‘ ì›ë¦¬:**\n1. ëœë¤ ë…¸ì´ì¦ˆì—ì„œ ì‹œì‘\n2. í…ìŠ¤íŠ¸ ì¡°ê±´ì— ë§ê²Œ ì ì§„ì ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°\n3. ìµœì¢…ì ìœ¼ë¡œ ê¹¨ë—í•œ ì´ë¯¸ì§€ ìƒì„±"
      },
      {
        "type": "code",
        "language": "python",
        "title": "Stable Diffusion ì‚¬ìš©í•˜ê¸°",
        "code": "# pip install diffusers transformers accelerate torch\n\nfrom diffusers import StableDiffusionPipeline\nimport torch\n\n# ëª¨ë¸ ë¡œë“œ (ì²˜ìŒ ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œë¨)\npipe = StableDiffusionPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    torch_dtype=torch.float16  # GPU ë©”ëª¨ë¦¬ ì ˆì•½\n)\npipe = pipe.to(\"cuda\")  # GPU ì‚¬ìš©\n\n# ì´ë¯¸ì§€ ìƒì„±\nprompt = \"a cute cat wearing sunglasses, digital art\"\nimage = pipe(prompt).images[0]\n\n# ì €ì¥\nimage.save(\"generated_cat.png\")"
      },
      {
        "type": "tip",
        "title": "í”„ë¡¬í”„íŠ¸ ì‘ì„± íŒ",
        "content": "**ì¢‹ì€ í”„ë¡¬í”„íŠ¸ êµ¬ì¡°:**\n`[ì£¼ì œ] + [ìŠ¤íƒ€ì¼] + [ë¶„ìœ„ê¸°] + [í’ˆì§ˆ í‚¤ì›Œë“œ]`\n\n**ì˜ˆì‹œ:**\n`a majestic lion, oil painting style, dramatic lighting, highly detailed, 8k`\n\n**í’ˆì§ˆ í–¥ìƒ í‚¤ì›Œë“œ:**\n- highly detailed, masterpiece, best quality\n- 8k, ultra HD, sharp focus\n- studio lighting, professional"
      }
    ]
  },
  "03_video-generation/video-gen": {
    "id": "03_video-generation/video-gen",
    "title": "AI ë¹„ë””ì˜¤ ìƒì„±",
    "category": "ai-tech",
    "subCategory": "03_video-generation",
    "language": "Python",
    "description": "í…ìŠ¤íŠ¸ë‚˜ ì´ë¯¸ì§€ë¡œë¶€í„° ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ëŠ” AI ê¸°ìˆ ì„ í•™ìŠµí•©ë‹ˆë‹¤.",
    "isPlaceholder": false,
    "sections": [
      {
        "type": "concept",
        "title": "AI ë¹„ë””ì˜¤ ìƒì„± ê¸°ìˆ ",
        "content": "**ì£¼ìš” ëª¨ë¸:**\n- **Runway Gen-2**: í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ â†’ ë¹„ë””ì˜¤\n- **Pika Labs**: ì§§ì€ ë¹„ë””ì˜¤ ìƒì„±\n- **Sora (OpenAI)**: ì¥ì‹œê°„ ê³ í’ˆì§ˆ ë¹„ë””ì˜¤\n- **AnimateDiff**: Stable Diffusion ê¸°ë°˜ ì• ë‹ˆë©”ì´ì…˜\n\n**ê¸°ìˆ  ë°©ì‹:**\n1. **í”„ë ˆì„ë³„ ìƒì„±**: ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ í™•ì¥\n2. **ì‹œê°„ì  ì¼ê´€ì„±**: Temporal attention í™œìš©\n3. **Video Diffusion**: 3D U-Netìœ¼ë¡œ ì‹œê³µê°„ ëª¨ë¸ë§"
      },
      {
        "type": "code",
        "language": "python",
        "title": "AnimateDiff ì˜ˆì œ",
        "code": "# pip install diffusers transformers accelerate\n\nfrom diffusers import AnimateDiffPipeline, MotionAdapter\nimport torch\n\n# Motion adapter ë¡œë“œ\nadapter = MotionAdapter.from_pretrained(\n    \"guoyww/animatediff-motion-adapter-v1-5-2\"\n)\n\n# íŒŒì´í”„ë¼ì¸ ìƒì„±\npipe = AnimateDiffPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-v1-5\",\n    motion_adapter=adapter,\n    torch_dtype=torch.float16\n).to(\"cuda\")\n\n# ë¹„ë””ì˜¤ ìƒì„±\nprompt = \"a cat walking in the garden\"\nframes = pipe(prompt, num_frames=16).frames[0]\n\n# GIFë¡œ ì €ì¥\nframes[0].save(\"animation.gif\", \n               save_all=True, \n               append_images=frames[1:], \n               duration=100, \n               loop=0)"
      }
    ]
  },
  "04_voice-synthesis/tts": {
    "id": "04_voice-synthesis/tts",
    "title": "TTS (Text-to-Speech) ìŒì„± í•©ì„±",
    "category": "ai-tech",
    "subCategory": "04_voice-synthesis",
    "language": "Python",
    "description": "í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” TTS ê¸°ìˆ ì„ í•™ìŠµí•©ë‹ˆë‹¤.",
    "isPlaceholder": false,
    "sections": [
      {
        "type": "concept",
        "title": "TTS ê¸°ìˆ  ê°œìš”",
        "content": "**Text-to-Speech íŒŒì´í”„ë¼ì¸:**\n\n1. **í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬**: ìˆ«ì, ì•½ì–´ ë³€í™˜\n2. **ìŒì†Œ ë³€í™˜**: í…ìŠ¤íŠ¸ â†’ ìŒì†Œ(Phoneme)\n3. **ìŒí–¥ ëª¨ë¸**: ìŒì†Œ â†’ ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨\n4. **ë³´ì½”ë”**: ìŠ¤í™íŠ¸ë¡œê·¸ë¨ â†’ ì˜¤ë””ì˜¤ íŒŒí˜•\n\n**ì£¼ìš” ëª¨ë¸:**\n- **Tacotron 2**: Attention ê¸°ë°˜ ìŒí–¥ ëª¨ë¸\n- **VITS**: End-to-end ê³ í’ˆì§ˆ TTS\n- **Coqui TTS**: ì˜¤í”ˆì†ŒìŠ¤ ë‹¤êµ­ì–´ TTS\n- **OpenAI TTS**: API ê¸°ë°˜ ê³ í’ˆì§ˆ ìŒì„±"
      },
      {
        "type": "code",
        "language": "python",
        "title": "gTTSë¡œ ê°„ë‹¨í•œ ìŒì„± ìƒì„±",
        "code": "# pip install gtts\n\nfrom gtts import gTTS\nimport os\n\n# í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜\ntext = \"ì•ˆë…•í•˜ì„¸ìš”, AI ìŒì„± í•©ì„± í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.\"\ntts = gTTS(text=text, lang='ko')  # í•œêµ­ì–´\n\n# MP3 íŒŒì¼ë¡œ ì €ì¥\ntts.save(\"output.mp3\")\n\n# ì¬ìƒ (Windows)\nos.system(\"start output.mp3\")"
      },
      {
        "type": "code",
        "language": "python",
        "title": "Coqui TTS (ê³ í’ˆì§ˆ)",
        "code": "# pip install TTS\n\nfrom TTS.api import TTS\n\n# ëª¨ë¸ ë¡œë“œ (ìë™ ë‹¤ìš´ë¡œë“œ)\ntts = TTS(model_name=\"tts_models/ko/css10/vits\")\n\n# ìŒì„± ìƒì„±\ntts.tts_to_file(\n    text=\"ì•ˆë…•í•˜ì„¸ìš”, ê³ í’ˆì§ˆ ìŒì„± í•©ì„±ì…ë‹ˆë‹¤.\",\n    file_path=\"output.wav\"\n)"
      }
    ]
  },
  "05_speech-recognition/whisper": {
    "id": "05_speech-recognition/whisper",
    "title": "Whisper ìŒì„± ì¸ì‹",
    "category": "ai-tech",
    "subCategory": "05_speech-recognition",
    "language": "Python",
    "description": "OpenAI Whisperë¥¼ ì‚¬ìš©í•œ ìŒì„± ì¸ì‹(STT)ì„ í•™ìŠµí•©ë‹ˆë‹¤.",
    "isPlaceholder": false,
    "sections": [
      {
        "type": "concept",
        "title": "Whisperë€?",
        "content": "**OpenAIì˜ ë²”ìš© ìŒì„± ì¸ì‹ ëª¨ë¸**\n\n**íŠ¹ì§•:**\n- ë‹¤êµ­ì–´ ì§€ì› (í•œêµ­ì–´ í¬í•¨ 99ê°œ ì–¸ì–´)\n- ìë™ ì–¸ì–´ ê°ì§€\n- ë²ˆì—­ ê¸°ëŠ¥ (â†’ ì˜ì–´)\n- ë…¸ì´ì¦ˆì— ê°•ê±´í•¨\n\n**ëª¨ë¸ í¬ê¸°:**\n- tiny (39M) â†’ base (74M) â†’ small (244M) â†’ medium (769M) â†’ large (1.55B)\n- í¬ê¸°ê°€ í´ìˆ˜ë¡ ì •í™•ë„ ë†’ìŒ"
      },
      {
        "type": "code",
        "language": "python",
        "title": "Whisper ìŒì„± ì¸ì‹",
        "code": "# pip install openai-whisper\n\nimport whisper\n\n# ëª¨ë¸ ë¡œë“œ\nmodel = whisper.load_model(\"base\")  # tiny, base, small, medium, large\n\n# ìŒì„± íŒŒì¼ ë³€í™˜\nresult = model.transcribe(\"audio.mp3\")\n\n# ê²°ê³¼ ì¶œë ¥\nprint(result[\"text\"])\n\n# ì–¸ì–´ ì§€ì • (í•œêµ­ì–´)\nresult = model.transcribe(\"korean_audio.mp3\", language=\"ko\")\n\n# íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ì¶œë ¥\nfor segment in result[\"segments\"]:\n    start = segment[\"start\"]\n    end = segment[\"end\"]\n    text = segment[\"text\"]\n    print(f\"[{start:.1f}s â†’ {end:.1f}s] {text}\")"
      },
      {
        "type": "tip",
        "title": "Whisper í™œìš© íŒ",
        "content": "**ì •í™•ë„ í–¥ìƒ:**\n- ì¡°ìš©í•œ í™˜ê²½ì—ì„œ ë…¹ìŒ\n- language íŒŒë¼ë¯¸í„° ëª…ì‹œì  ì§€ì •\n- medium ì´ìƒ ëª¨ë¸ ì‚¬ìš©\n\n**ìš©ë„:**\n- íšŒì˜ë¡ ìë™ ì‘ì„±\n- ìœ íŠœë¸Œ ìë§‰ ìƒì„±\n- íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸"
      }
    ]
  },
  "06_face-recognition/deepface": {
    "id": "06_face-recognition/deepface",
    "title": "DeepFace ì–¼êµ´ ì¸ì‹",
    "category": "ai-tech",
    "subCategory": "06_face-recognition",
    "language": "Python",
    "description": "DeepFace ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•œ ì–¼êµ´ ì¸ì‹ê³¼ ë¶„ì„ì„ í•™ìŠµí•©ë‹ˆë‹¤.",
    "isPlaceholder": false,
    "sections": [
      {
        "type": "concept",
        "title": "DeepFace ê¸°ëŠ¥",
        "content": "**ì–¼êµ´ ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬**\n\n**ì£¼ìš” ê¸°ëŠ¥:**\n1. **ì–¼êµ´ ê²€ì¦ (Verification)**: ë‘ ì–¼êµ´ì´ ê°™ì€ ì‚¬ëŒì¸ì§€\n2. **ì–¼êµ´ ì¸ì‹ (Recognition)**: DBì—ì„œ ì¼ì¹˜í•˜ëŠ” ì–¼êµ´ ì°¾ê¸°\n3. **ì–¼êµ´ ë¶„ì„ (Analysis)**: ë‚˜ì´, ì„±ë³„, ê°ì •, ì¸ì¢… ì¶”ì •\n\n**ì§€ì› ëª¨ë¸:**\nVGG-Face, Facenet, OpenFace, DeepFace, ArcFace ë“±"
      },
      {
        "type": "code",
        "language": "python",
        "title": "DeepFace ì‚¬ìš©í•˜ê¸°",
        "code": "# pip install deepface\n\nfrom deepface import DeepFace\n\n# 1. ì–¼êµ´ ê²€ì¦ (ë‘ ì–¼êµ´ ë¹„êµ)\nresult = DeepFace.verify(\n    img1_path=\"face1.jpg\",\n    img2_path=\"face2.jpg\"\n)\nprint(f\"ê°™ì€ ì‚¬ëŒ: {result['verified']}\")\nprint(f\"ê±°ë¦¬: {result['distance']}\")\n\n# 2. ì–¼êµ´ ë¶„ì„\nanalysis = DeepFace.analyze(\n    img_path=\"face.jpg\",\n    actions=['age', 'gender', 'emotion']\n)\nprint(f\"ë‚˜ì´: {analysis[0]['age']}\")\nprint(f\"ì„±ë³„: {analysis[0]['dominant_gender']}\")\nprint(f\"ê°ì •: {analysis[0]['dominant_emotion']}\")\n\n# 3. ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ\nembedding = DeepFace.represent(\n    img_path=\"face.jpg\",\n    model_name=\"Facenet\"\n)"
      }
    ]
  },
  "07_pose-estimation/mediapipe-pose": {
    "id": "07_pose-estimation/mediapipe-pose",
    "title": "MediaPipe í¬ì¦ˆ ì¶”ì •",
    "category": "ai-tech",
    "subCategory": "07_pose-estimation",
    "language": "Python",
    "description": "Google MediaPipeë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ì¸ì²´ í¬ì¦ˆ ì¶”ì •ì„ í•™ìŠµí•©ë‹ˆë‹¤.",
    "isPlaceholder": false,
    "sections": [
      {
        "type": "concept",
        "title": "MediaPipe Poseë€?",
        "content": "**Googleì˜ ì‹¤ì‹œê°„ í¬ì¦ˆ ì¶”ì • ë¼ì´ë¸ŒëŸ¬ë¦¬**\n\n**íŠ¹ì§•:**\n- 33ê°œì˜ ì‹ ì²´ ëœë“œë§ˆí¬ ê°ì§€\n- ì‹¤ì‹œê°„ ì²˜ë¦¬ (30+ FPS)\n- CPUì—ì„œë„ ë¹ ë¥¸ ì¶”ë¡ \n- ì›¹, ëª¨ë°”ì¼, ë°ìŠ¤í¬í†± ì§€ì›\n\n**ëœë“œë§ˆí¬ ì˜ˆì‹œ:**\n- 0: ì½” / 11-12: ì–´ê¹¨ / 23-24: ì—‰ë©ì´\n- 15-16: ì†ëª© / 27-28: ë°œëª©"
      },
      {
        "type": "code",
        "language": "python",
        "title": "ì›¹ìº  ì‹¤ì‹œê°„ í¬ì¦ˆ ì¶”ì •",
        "code": "# pip install mediapipe opencv-python\n\nimport cv2\nimport mediapipe as mp\n\n# MediaPipe ì´ˆê¸°í™”\nmp_pose = mp.solutions.pose\nmp_draw = mp.solutions.drawing_utils\npose = mp_pose.Pose()\n\n# ì›¹ìº  ì—´ê¸°\ncap = cv2.VideoCapture(0)\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    # RGB ë³€í™˜ (MediaPipeëŠ” RGB ì…ë ¥)\n    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    \n    # í¬ì¦ˆ ì¶”ì •\n    results = pose.process(rgb)\n    \n    # ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°\n    if results.pose_landmarks:\n        mp_draw.draw_landmarks(\n            frame,\n            results.pose_landmarks,\n            mp_pose.POSE_CONNECTIONS\n        )\n        \n        # íŠ¹ì • ëœë“œë§ˆí¬ ì¢Œí‘œ ì–»ê¸° (ì˜ˆ: ì™¼ìª½ ì†ëª©)\n        left_wrist = results.pose_landmarks.landmark[15]\n        print(f\"ì™¼ìª½ ì†ëª©: x={left_wrist.x:.2f}, y={left_wrist.y:.2f}\")\n    \n    cv2.imshow('Pose Estimation', frame)\n    \n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()"
      },
      {
        "type": "tip",
        "title": "í™œìš© ì‚¬ë¡€",
        "content": "**í¬ì¦ˆ ì¶”ì • í™œìš©:**\n- í”¼íŠ¸ë‹ˆìŠ¤ ì•± (ìì„¸ êµì •)\n- ê²Œì„ ì»¨íŠ¸ë¡¤ëŸ¬ (ë™ì‘ ì¸ì‹)\n- ìŠ¤í¬ì¸  ë¶„ì„\n- ë¬¼ë¦¬ ì¹˜ë£Œ ë³´ì¡°\n- ìˆ˜í™” ì¸ì‹"
      }
    ]
  },
  "08_ocr/easyocr": {
    "id": "08_ocr/easyocr",
    "title": "EasyOCR ë¬¸ì ì¸ì‹",
    "category": "ai-tech",
    "subCategory": "08_ocr",
    "language": "Python",
    "description": "EasyOCRì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë‚´ ë¬¸ì ì¸ì‹(OCR)ì„ í•™ìŠµí•©ë‹ˆë‹¤.",
    "isPlaceholder": false,
    "sections": [
      {
        "type": "concept",
        "title": "OCR (Optical Character Recognition)",
        "content": "**ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ**\n\n**EasyOCR íŠ¹ì§•:**\n- 80+ ì–¸ì–´ ì§€ì› (í•œêµ­ì–´ í¬í•¨)\n- ë”¥ëŸ¬ë‹ ê¸°ë°˜ ê³ ì •í™•ë„\n- ì„¤ì¹˜ ë° ì‚¬ìš© ê°„í¸\n- GPU ê°€ì† ì§€ì›\n\n**ì²˜ë¦¬ ê³¼ì •:**\n1. í…ìŠ¤íŠ¸ ì˜ì—­ ê²€ì¶œ (CRAFT)\n2. ë¬¸ì ì¸ì‹ (CRNN)\n3. ê²°ê³¼ í›„ì²˜ë¦¬"
      },
      {
        "type": "code",
        "language": "python",
        "title": "EasyOCR ì‚¬ìš©í•˜ê¸°",
        "code": "# pip install easyocr\n\nimport easyocr\n\n# ë¦¬ë” ìƒì„± (ì–¸ì–´ ì§€ì •)\nreader = easyocr.Reader(['ko', 'en'])  # í•œêµ­ì–´ + ì˜ì–´\n\n# ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\nresult = reader.readtext('document.jpg')\n\n# ê²°ê³¼ ì¶œë ¥\nfor detection in result:\n    bbox = detection[0]      # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ\n    text = detection[1]      # ì¸ì‹ëœ í…ìŠ¤íŠ¸\n    confidence = detection[2] # ì‹ ë¢°ë„\n    \n    print(f\"í…ìŠ¤íŠ¸: {text}\")\n    print(f\"ì‹ ë¢°ë„: {confidence:.2f}\")\n    print(f\"ìœ„ì¹˜: {bbox}\")\n    print(\"---\")\n\n# í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ\ntexts = reader.readtext('document.jpg', detail=0)\nprint(\"\\n\".join(texts))"
      },
      {
        "type": "code",
        "language": "python",
        "title": "OCR ê²°ê³¼ ì‹œê°í™”",
        "code": "import cv2\nimport easyocr\n\nreader = easyocr.Reader(['ko', 'en'])\nimage = cv2.imread('document.jpg')\n\nresult = reader.readtext('document.jpg')\n\nfor detection in result:\n    # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n    pts = detection[0]\n    pts = [(int(p[0]), int(p[1])) for p in pts]\n    \n    cv2.polylines(image, [np.array(pts)], True, (0, 255, 0), 2)\n    cv2.putText(image, detection[1], pts[0], \n                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n\ncv2.imwrite('ocr_result.jpg', image)"
      }
    ]
  },
  "09_chatbot/langchain": {
    "id": "09_chatbot/langchain",
    "title": "LangChain ì±—ë´‡ ê°œë°œ",
    "category": "ai-tech",
    "subCategory": "09_chatbot",
    "language": "Python",
    "description": "LangChainì„ í™œìš©í•œ LLM ê¸°ë°˜ ì±—ë´‡ ê°œë°œì„ í•™ìŠµí•©ë‹ˆë‹¤.",
    "isPlaceholder": false,
    "sections": [
      {
        "type": "concept",
        "title": "LangChainì´ë€?",
        "content": "**LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ í”„ë ˆì„ì›Œí¬**\n\n**í•µì‹¬ ê°œë…:**\n- **Chain**: ì—¬ëŸ¬ ì»´í¬ë„ŒíŠ¸ ì—°ê²°\n- **Agent**: ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ììœ¨ AI\n- **Memory**: ëŒ€í™” ê¸°ë¡ ê´€ë¦¬\n- **Retrieval**: ë¬¸ì„œ ê²€ìƒ‰ (RAG)\n\n**ìš©ë„:**\n- ëŒ€í™”í˜• ì±—ë´‡\n- ë¬¸ì„œ ê¸°ë°˜ QA\n- ì½”ë“œ ìƒì„±/ë¶„ì„\n- ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸"
      },
      {
        "type": "code",
        "language": "python",
        "title": "LangChain ì±—ë´‡ ê¸°ì´ˆ",
        "code": "# pip install langchain langchain-openai\n\nfrom langchain_openai import ChatOpenAI\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.chains import ConversationChain\n\n# LLM ì´ˆê¸°í™”\nllm = ChatOpenAI(\n    model=\"gpt-3.5-turbo\",\n    temperature=0.7,\n    openai_api_key=\"your-api-key\"\n)\n\n# ë©”ëª¨ë¦¬ ì„¤ì • (ëŒ€í™” ê¸°ë¡ ìœ ì§€)\nmemory = ConversationBufferMemory()\n\n# ëŒ€í™” ì²´ì¸ ìƒì„±\nconversation = ConversationChain(\n    llm=llm,\n    memory=memory,\n    verbose=True\n)\n\n# ëŒ€í™” ì‹¤í–‰\nresponse1 = conversation.predict(input=\"ì•ˆë…•! ë‚˜ëŠ” ê¹€ì² ìˆ˜ì•¼.\")\nprint(response1)\n\nresponse2 = conversation.predict(input=\"ë‚´ ì´ë¦„ì´ ë­ì˜€ì§€?\")\nprint(response2)  # ì´ì „ ëŒ€í™” ê¸°ì–µí•¨"
      },
      {
        "type": "code",
        "language": "python",
        "title": "RAG (ë¬¸ì„œ ê¸°ë°˜ QA)",
        "code": "from langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.vectorstores import FAISS\nfrom langchain.chains import RetrievalQA\n\n# 1. ë¬¸ì„œ ë¡œë“œ\nloader = TextLoader('document.txt')\ndocuments = loader.load()\n\n# 2. í…ìŠ¤íŠ¸ ë¶„í• \nsplitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\ntexts = splitter.split_documents(documents)\n\n# 3. ì„ë² ë”© ë° ë²¡í„° ì €ì¥ì†Œ ìƒì„±\nembeddings = OpenAIEmbeddings()\nvectorstore = FAISS.from_documents(texts, embeddings)\n\n# 4. QA ì²´ì¸ ìƒì„±\nqa_chain = RetrievalQA.from_chain_type(\n    llm=llm,\n    retriever=vectorstore.as_retriever()\n)\n\n# 5. ì§ˆë¬¸í•˜ê¸°\nanswer = qa_chain.run(\"ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì´ ë­ì•¼?\")\nprint(answer)"
      }
    ]
  },
  "10_code-generation/ai-coding": {
    "id": "10_code-generation/ai-coding",
    "title": "AI ì½”ë“œ ìƒì„±",
    "category": "ai-tech",
    "subCategory": "10_code-generation",
    "language": "Python",
    "description": "AIë¥¼ í™œìš©í•œ ì½”ë“œ ìƒì„±ê³¼ í”„ë¡œê·¸ë˜ë° ë³´ì¡° ë„êµ¬ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.",
    "isPlaceholder": false,
    "sections": [
      {
        "type": "concept",
        "title": "AI ì½”ë”© ë„êµ¬",
        "content": "**ì½”ë“œ ìƒì„± AI ì¢…ë¥˜:**\n\n**1. ì½”ë“œ ìë™ ì™„ì„±**\n- GitHub Copilot\n- Amazon CodeWhisperer\n- Tabnine\n\n**2. ì½”ë“œ ìƒì„± LLM**\n- GPT-4, Claude\n- Code Llama\n- StarCoder\n\n**3. íŠ¹í™” ë„êµ¬**\n- Cursor (AI ì—ë””í„°)\n- Replit AI\n- Claude Code"
      },
      {
        "type": "code",
        "language": "python",
        "title": "OpenAI APIë¡œ ì½”ë“œ ìƒì„±",
        "code": "from openai import OpenAI\n\nclient = OpenAI(api_key=\"your-api-key\")\n\ndef generate_code(prompt):\n    response = client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a Python expert. Generate clean, well-documented code.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": prompt\n            }\n        ],\n        temperature=0.2  # ë‚®ì„ìˆ˜ë¡ ì¼ê´€ëœ ì¶œë ¥\n    )\n    return response.choices[0].message.content\n\n# ì‚¬ìš© ì˜ˆì‹œ\ncode = generate_code(\n    \"íŒŒì¼ì—ì„œ JSONì„ ì½ê³  íŠ¹ì • í‚¤ì˜ ê°’ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ ì‘ì„±\"\n)\nprint(code)"
      },
      {
        "type": "tip",
        "title": "AI ì½”ë”© ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤",
        "content": "**íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì‘ì„±:**\n1. ëª…í™•í•œ ìš”êµ¬ì‚¬í•­ ëª…ì‹œ\n2. ì…ì¶œë ¥ ì˜ˆì‹œ ì œê³µ\n3. ì‚¬ìš©í•  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì§€ì •\n4. ì—ëŸ¬ ì²˜ë¦¬ ìš”ì²­\n\n**ì£¼ì˜ì‚¬í•­:**\n- ìƒì„±ëœ ì½”ë“œ ë°˜ë“œì‹œ ê²€í† \n- ë³´ì•ˆ ì·¨ì•½ì  í™•ì¸\n- ë¼ì´ì„ ìŠ¤ ë¬¸ì œ ê³ ë ¤\n- ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±"
      }
    ]
  }
}
